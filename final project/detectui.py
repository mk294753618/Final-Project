# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'detectui.ui'
#
# Created by: PyQt5 UI code generator 5.15.9
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import argparse
import sys
import numpy as np

import torch
from torch.autograd import Variable
from torchvision import transforms

from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtCore import *
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
from PyQt5 import uic

from models import load_model
from utils.utils import nms, rescale_boxes, load_classes
from utils.transforms import DEFAULT_TRANSFORMS, Resize

import cv2


class Ui_Form(QtWidgets.QMainWindow):

    def __init__(self):
        super().__init__()
        self.ui = uic.loadUi('detectui.ui')
        self.timer_video = QtCore.QTimer()
        self.openfile_name_model = None
        self.cap = cv2.VideoCapture()
        self.init_slot()
        self.ui.show()

    def init_slot(self):
        self.ui.Button_1.clicked.connect(self.open_model)
        self.ui.Button_2.clicked.connect(self.initModel)
        self.ui.Button_3.clicked.connect(self.button_image)
        self.ui.Button_4.clicked.connect(self.button_video_open)
        self.timer_video.timeout.connect(self.show_video_frame)


    def open_model(self):
        self.openfile_name_model, _ = QtWidgets.QFileDialog.getOpenFileName(self, '选择weights文件',
                                                                  'weights/')
        if not self.openfile_name_model:
            QtWidgets.QMessageBox.warning(self, u"Warning", u"打开权重失败", buttons=QtWidgets.QMessageBox.Ok,
                                          defaultButton=QtWidgets.QMessageBox.Ok)
        else:
            print('加载weights文件地址为：' + str(self.openfile_name_model))

    def initModel(self):
        parser = argparse.ArgumentParser(description="Detect objects on images.")
        parser.add_argument('--model', type=str, default='./config/yolov3_spp.cfg', help='path to model file')
        parser.add_argument("--weights", type=str, default="./checkpoints/yolov3_ckpt_30.pth",
                            help="Path to weights or checkpoint file (.weights or .pth)")
        parser.add_argument("--classes", type=str, default="./data/valorant.names",
                            help="Path to classes label file (.names)")
        parser.add_argument("--batch_size", type=int, default=1, help="Size of each image batch")
        parser.add_argument("--img_size", type=int, default=416, help="Size of each image dimension for yolo")
        parser.add_argument("--n_cpu", type=int, default=0, help="Number of cpu threads to use during batch generation")
        parser.add_argument("--conf_thres", type=float, default=0.3, help="Object confidence threshold")
        parser.add_argument("--nms_thres", type=float, default=0.5, help="IOU threshold for non-maximum suppression")

        self.args = parser.parse_args()

        self.classes = load_classes(self.args.classes)
        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'

        if self.openfile_name_model is not None:
            weight_path = self.openfile_name_model
        else:
            weight_path = self.args.weights
        self.model = load_model(device, self.args.model, weight_path)
        QtWidgets.QMessageBox.information(self, u"Notice", u"模型加载完成", buttons=QtWidgets.QMessageBox.Ok,
                                          defaultButton=QtWidgets.QMessageBox.Ok)

    def detect(self, img):
        trans_img, img_detections = self.detect_box(
            self.model,
            img,
            self.args.conf_thres,
            self.args.nms_thres,
            self.args.img_size)
        re_img = self.draw_image(
            img, img_detections, self.args.img_size, self.classes)
        return re_img

    def detect_box(self, model, img, conf_thres, nms_thres, img_size):
        model.eval()
        img = img[:, :, ::-1]
        Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor
        img = np.array(img, dtype=np.uint8)
        box = np.zeros((1, 5))
        transform = transforms.Compose([DEFAULT_TRANSFORMS, Resize(img_size)])
        img, _ = transform((img, box))
        img = torch.unsqueeze(img, dim=0)
        img = Variable(img.type(Tensor))

        img_detections = []
        with torch.no_grad():
            detections = model(img)
            detections = nms(detections, conf_thres, nms_thres)
            img_detections.extend(detections)

        return img, img_detections


    def draw_image(self, image, detections, img_size, classes):
        img = image
        for detection in detections:
            detection = rescale_boxes(detection, img_size, img.shape[:2])
            y, x = img.shape[:2]
            for x1, y1, x2, y2, conf, cls_pred in detection:
                if x1 > x * 0.2 and y1 > y * 0.2 and x2 < x * 0.8 and y2 < y * 0.8:
                    if int(cls_pred) == 0:
                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                    else:
                        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    img = cv2.putText(img, '{} {:.3f}'.format(classes[int(cls_pred)], conf), (int(x1), int(y1)),
                                          font, 1, (int(x2), int(y2)), 4)
        return img

    def button_image(self):
        print('button_image_open')
        img_name, _ = QtWidgets.QFileDialog.getOpenFileName(self, "打开图片", "samples/",
                                                            "*.jpg;;*.png;;All Files(*)")

        if not img_name:
            QtWidgets.QMessageBox.warning(self, u"Warning", u"打开图片失败", buttons=QtWidgets.QMessageBox.Ok,
                                          defaultButton=QtWidgets.QMessageBox.Ok)
        else:
            img = cv2.imread(img_name)
            img_o = cv2.imread(img_name)
            info_show = self.detect(img)
            self.result = cv2.cvtColor(info_show, cv2.COLOR_BGR2BGRA)
            self.origin = cv2.cvtColor(img_o, cv2.COLOR_BGR2BGRA)
            self.originImg = QtGui.QImage(self.origin.data, self.origin.shape[1], self.origin.shape[0],
                                      QtGui.QImage.Format_RGB32)
            self.resultImg = QtGui.QImage(self.result.data, self.result.shape[1], self.result.shape[0],
                                      QtGui.QImage.Format_RGB32)
            self.ui.label_1.setPixmap(QtGui.QPixmap.fromImage(self.originImg))
            self.ui.label_1.setScaledContents(True)
            self.ui.label_2.setPixmap(QtGui.QPixmap.fromImage(self.resultImg))
            self.ui.label_2.setScaledContents(True)

    def button_video_open(self):
        video_name, _ = QtWidgets.QFileDialog.getOpenFileName(self, "打开视频",
                                                              "samples/", "*.mp4;;*.avi;;All Files(*)")
        flag = self.cap.open(video_name)
        if flag == False:
            QtWidgets.QMessageBox.warning(self, u"Warning", u"打开视频失败", buttons=QtWidgets.QMessageBox.Ok,
                                          defaultButton=QtWidgets.QMessageBox.Ok)
        else:
            self.timer_video.start(30)
            self.ui.Button_4.setDisabled(True)
            self.ui.Button_3.setDisabled(True)



    def show_video_frame(self):
        flag, img = self.cap.read()
        _, img_o = self.cap.read()
        if img is not None:
            info_show = self.detect(img)
            self.result = cv2.cvtColor(info_show, cv2.COLOR_BGR2BGRA)
            self.origin = cv2.cvtColor(img_o, cv2.COLOR_BGR2BGRA)
            self.originImg = QtGui.QImage(self.origin.data, self.origin.shape[1], self.origin.shape[0],
                                          QtGui.QImage.Format_RGB32)
            self.resultImg = QtGui.QImage(self.result.data, self.result.shape[1], self.result.shape[0],
                                          QtGui.QImage.Format_RGB32)
            self.ui.label_1.setPixmap(QtGui.QPixmap.fromImage(self.originImg))
            self.ui.label_1.setScaledContents(True)
            self.ui.label_2.setPixmap(QtGui.QPixmap.fromImage(self.resultImg))
            self.ui.label_2.setScaledContents(True)

        else:
            self.timer_video.stop()
            self.cap.release()
            self.ui.label_1.clear()
            self.ui.label_2.clear()
            self.ui.Button_4.setDisabled(False)
            self.ui.Button_3.setDisabled(False)


if __name__ == '__main__':
    app = QtWidgets.QApplication(sys.argv)
    current_ui = Ui_Form()
    current_ui.show()
    sys.exit(app.exec_())






